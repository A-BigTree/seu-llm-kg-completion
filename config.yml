# Configuration file for the application

# Logging configuration
logging:
  level: INFO
  format: '[%(asctime)s][%(name)s][%(levelname)s][%(funcName)s] - %(message)s'

# Solr configuration
solr:
  host: http://localhost:8983/solr/
  cores:
    - wiki0
    - wiki1
    - wiki2
    - wiki3
    - wiki4
  # Initial data configuration
  update:
    data-dir: ./data/datasets/wikipedia
    update-url: /update?commit=true
    queue-size: 10
    produce-thread: 1
    consume-thread: 20
  # Query configuration
  query:
    query-url: /select?%s
    query-params:
      q: "*:*"
      fl: value
      start: 0
      rows: 100

# Datasets configuration for pre-task
datasets:
  path: ./data/pre/
  types:
    - DB15K
    # - FB15K
    # - FB15K-237
    # - YAGO15K

# OpenAI GPT configuration
gpt:
  api-url: https://api.openai-proxy.org/v1/chat/completions
  api-key: <API_KEY>
  proxy: null
  model: gpt-3.5-turbo-0125
  prompt: "Generate 20 brief natural language descriptions(less than 10 words) for the KG triplet (%s,,%s) with the '%s' replaced as <H> and the '%s' as <T>"
  relation-example-num: 3
  request-thread: 0
  request-timeout: 20


# Training configuration
training:
  data_dir: ./datasets/
  dataset: FB15k-237
  save: True
  save_dir: ./data/models/
  cuda: 0
  model: GAT
  epochs: 3000
  batch_size: 128
  lr: 0.0005
  dropout: 0.3
  weight_decay: 0.00001
  seed: 10010
  num_layer: 3
  dim: 256
  r_dim: 256
  k_w: 10
  k_h: 20
  n_heads: 2
  pre_trained: False
  encoder: False
  patience: 5
  eval_freq: 10
  lr_reduce_freq: 500
  gamma: 1.0
  bias: 1,
  neg_num: 2
  alpha: 0.2
  out_channels: 32
  kernel_size: 3

tasks:
  solr-init: False
  data-init: False
  model-train: False
